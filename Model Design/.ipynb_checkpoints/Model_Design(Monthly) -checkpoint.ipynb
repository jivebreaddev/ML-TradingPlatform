{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Loading Training Sets </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_in = open(\"Training_Sets/N_X5monthly.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Training_Sets/N_Y5monthly.pickle\",\"rb\")\n",
    "Y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Train/Test Split </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.10)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "Y_train = np.asarray(Y_train)\n",
    "Y_test = np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <b> K nearest Neigbor </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bikal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.49146757679180886\n",
      "2 0.4948805460750853\n",
      "3 0.5187713310580204\n",
      "4 0.4880546075085324\n",
      "5 0.49146757679180886\n",
      "6 0.5187713310580204\n",
      "7 0.5017064846416383\n",
      "8 0.5051194539249146\n",
      "9 0.4948805460750853\n",
      "10 0.5358361774744027\n",
      "11 0.49146757679180886\n",
      "12 0.5392491467576792\n",
      "13 0.5187713310580204\n",
      "14 0.5324232081911263\n",
      "15 0.5255972696245734\n",
      "16 0.5221843003412969\n",
      "17 0.5187713310580204\n",
      "18 0.5221843003412969\n",
      "19 0.5119453924914675\n",
      "20 0.48464163822525597\n",
      "21 0.5085324232081911\n",
      "22 0.5119453924914675\n",
      "23 0.5187713310580204\n",
      "24 0.5221843003412969\n",
      "25 0.5324232081911263\n",
      "26 0.5255972696245734\n",
      "27 0.515358361774744\n",
      "28 0.5051194539249146\n",
      "29 0.5187713310580204\n",
      "30 0.49146757679180886\n",
      "31 0.515358361774744\n",
      "32 0.4880546075085324\n",
      "33 0.49829351535836175\n",
      "34 0.4709897610921502\n",
      "35 0.4880546075085324\n",
      "36 0.49829351535836175\n",
      "37 0.5017064846416383\n",
      "38 0.4948805460750853\n",
      "39 0.5119453924914675\n",
      "40 0.5017064846416383\n",
      "41 0.5187713310580204\n",
      "42 0.5187713310580204\n",
      "43 0.5255972696245734\n",
      "44 0.5051194539249146\n",
      "45 0.5221843003412969\n",
      "46 0.5085324232081911\n",
      "47 0.5085324232081911\n",
      "48 0.5051194539249146\n",
      "49 0.5187713310580204\n",
      "50 0.5290102389078498\n",
      "51 0.5221843003412969\n",
      "52 0.5290102389078498\n",
      "53 0.4948805460750853\n",
      "54 0.49146757679180886\n",
      "55 0.5051194539249146\n",
      "56 0.5017064846416383\n",
      "57 0.5119453924914675\n",
      "58 0.5017064846416383\n",
      "59 0.5017064846416383\n",
      "60 0.5119453924914675\n",
      "61 0.5085324232081911\n",
      "62 0.49829351535836175\n",
      "63 0.5051194539249146\n",
      "64 0.5119453924914675\n",
      "65 0.515358361774744\n",
      "66 0.4880546075085324\n",
      "67 0.48464163822525597\n",
      "68 0.49146757679180886\n",
      "69 0.49829351535836175\n",
      "70 0.4812286689419795\n",
      "71 0.5085324232081911\n",
      "72 0.49146757679180886\n",
      "73 0.49829351535836175\n",
      "74 0.4812286689419795\n",
      "75 0.49146757679180886\n",
      "76 0.4812286689419795\n",
      "77 0.4880546075085324\n",
      "78 0.4880546075085324\n",
      "79 0.49829351535836175\n",
      "80 0.5051194539249146\n",
      "81 0.5119453924914675\n",
      "82 0.4948805460750853\n",
      "83 0.5017064846416383\n",
      "84 0.49829351535836175\n",
      "85 0.5017064846416383\n",
      "86 0.49146757679180886\n",
      "87 0.515358361774744\n",
      "88 0.4778156996587031\n",
      "89 0.48464163822525597\n",
      "90 0.47440273037542663\n",
      "91 0.49146757679180886\n",
      "92 0.46757679180887374\n",
      "93 0.4778156996587031\n",
      "94 0.4539249146757679\n",
      "95 0.4812286689419795\n",
      "96 0.4641638225255973\n",
      "97 0.4812286689419795\n",
      "98 0.4709897610921502\n",
      "99 0.4948805460750853\n",
      "100 0.4778156996587031\n",
      "101 0.5051194539249146\n",
      "102 0.4880546075085324\n",
      "103 0.49829351535836175\n",
      "104 0.48464163822525597\n",
      "105 0.49146757679180886\n",
      "106 0.4880546075085324\n",
      "107 0.4880546075085324\n",
      "108 0.4778156996587031\n",
      "109 0.4812286689419795\n",
      "110 0.4641638225255973\n",
      "111 0.4778156996587031\n",
      "112 0.47440273037542663\n",
      "113 0.4812286689419795\n",
      "114 0.4778156996587031\n",
      "115 0.4948805460750853\n",
      "116 0.4641638225255973\n",
      "117 0.4812286689419795\n",
      "118 0.47440273037542663\n",
      "119 0.47440273037542663\n",
      "120 0.47440273037542663\n",
      "121 0.4948805460750853\n",
      "122 0.47440273037542663\n",
      "123 0.4880546075085324\n",
      "124 0.49146757679180886\n",
      "125 0.5017064846416383\n",
      "126 0.48464163822525597\n",
      "127 0.5085324232081911\n",
      "128 0.48464163822525597\n",
      "129 0.4948805460750853\n",
      "130 0.47440273037542663\n",
      "131 0.5017064846416383\n",
      "132 0.4948805460750853\n",
      "133 0.49146757679180886\n",
      "134 0.4948805460750853\n",
      "135 0.5051194539249146\n",
      "136 0.49146757679180886\n",
      "137 0.4948805460750853\n",
      "138 0.4778156996587031\n",
      "139 0.49146757679180886\n",
      "140 0.4778156996587031\n",
      "141 0.4948805460750853\n",
      "142 0.49146757679180886\n",
      "143 0.5017064846416383\n",
      "144 0.4812286689419795\n",
      "145 0.4948805460750853\n",
      "146 0.4812286689419795\n",
      "147 0.5017064846416383\n",
      "148 0.4812286689419795\n",
      "149 0.5017064846416383\n",
      "150 0.4880546075085324\n",
      "151 0.5017064846416383\n",
      "152 0.4880546075085324\n",
      "153 0.49146757679180886\n",
      "154 0.4778156996587031\n",
      "155 0.4880546075085324\n",
      "156 0.4948805460750853\n",
      "157 0.4812286689419795\n",
      "158 0.4948805460750853\n",
      "159 0.5017064846416383\n",
      "160 0.49829351535836175\n",
      "161 0.5017064846416383\n",
      "162 0.5051194539249146\n",
      "163 0.5051194539249146\n",
      "164 0.5085324232081911\n",
      "165 0.5187713310580204\n",
      "166 0.5119453924914675\n",
      "167 0.515358361774744\n",
      "168 0.5221843003412969\n",
      "169 0.5221843003412969\n",
      "170 0.515358361774744\n",
      "171 0.5119453924914675\n",
      "172 0.5085324232081911\n",
      "173 0.5221843003412969\n",
      "174 0.5051194539249146\n",
      "175 0.5221843003412969\n",
      "176 0.5187713310580204\n",
      "177 0.5255972696245734\n",
      "178 0.5119453924914675\n",
      "179 0.5187713310580204\n",
      "180 0.5119453924914675\n",
      "181 0.5460750853242321\n",
      "182 0.5255972696245734\n",
      "183 0.5358361774744027\n",
      "184 0.5255972696245734\n",
      "185 0.5358361774744027\n",
      "186 0.5290102389078498\n",
      "187 0.5392491467576792\n",
      "188 0.5392491467576792\n",
      "189 0.5631399317406144\n",
      "190 0.5426621160409556\n",
      "191 0.552901023890785\n",
      "192 0.5290102389078498\n",
      "193 0.552901023890785\n",
      "194 0.5324232081911263\n",
      "195 0.552901023890785\n",
      "196 0.5392491467576792\n",
      "197 0.5563139931740614\n",
      "198 0.5563139931740614\n",
      "199 0.5597269624573379\n",
      "200 0.5392491467576792\n",
      "201 0.5665529010238908\n",
      "202 0.552901023890785\n",
      "203 0.5665529010238908\n",
      "204 0.5597269624573379\n",
      "205 0.5631399317406144\n",
      "206 0.5665529010238908\n",
      "207 0.5733788395904437\n",
      "208 0.5631399317406144\n",
      "209 0.5597269624573379\n",
      "210 0.5665529010238908\n",
      "211 0.5597269624573379\n",
      "212 0.5563139931740614\n",
      "213 0.5597269624573379\n",
      "214 0.5665529010238908\n",
      "215 0.5733788395904437\n",
      "216 0.5802047781569966\n",
      "217 0.5938566552901023\n",
      "218 0.5767918088737202\n",
      "219 0.5665529010238908\n",
      "220 0.5597269624573379\n",
      "221 0.5563139931740614\n",
      "222 0.552901023890785\n",
      "223 0.552901023890785\n",
      "224 0.5563139931740614\n",
      "225 0.5494880546075085\n",
      "226 0.5494880546075085\n",
      "227 0.5563139931740614\n",
      "228 0.552901023890785\n",
      "229 0.5563139931740614\n",
      "230 0.5494880546075085\n",
      "231 0.5631399317406144\n",
      "232 0.5460750853242321\n",
      "233 0.552901023890785\n",
      "234 0.5460750853242321\n",
      "235 0.552901023890785\n",
      "236 0.5563139931740614\n",
      "237 0.5699658703071673\n",
      "238 0.5767918088737202\n",
      "239 0.5665529010238908\n",
      "240 0.5597269624573379\n",
      "241 0.5699658703071673\n",
      "242 0.5631399317406144\n",
      "243 0.5733788395904437\n",
      "244 0.5665529010238908\n",
      "245 0.5631399317406144\n",
      "246 0.5699658703071673\n",
      "247 0.5597269624573379\n",
      "248 0.552901023890785\n",
      "249 0.5631399317406144\n",
      "250 0.5563139931740614\n",
      "251 0.552901023890785\n",
      "252 0.552901023890785\n",
      "253 0.552901023890785\n",
      "254 0.5426621160409556\n",
      "255 0.5358361774744027\n",
      "256 0.5358361774744027\n",
      "257 0.5290102389078498\n",
      "258 0.5290102389078498\n",
      "259 0.5392491467576792\n",
      "260 0.5392491467576792\n",
      "261 0.5426621160409556\n",
      "262 0.5392491467576792\n",
      "263 0.5563139931740614\n",
      "264 0.5392491467576792\n",
      "265 0.5494880546075085\n",
      "266 0.552901023890785\n",
      "267 0.552901023890785\n",
      "268 0.5460750853242321\n",
      "269 0.5460750853242321\n",
      "270 0.5460750853242321\n",
      "271 0.5460750853242321\n",
      "272 0.5494880546075085\n",
      "273 0.5733788395904437\n",
      "274 0.5460750853242321\n",
      "275 0.5494880546075085\n",
      "276 0.5494880546075085\n",
      "277 0.5494880546075085\n",
      "278 0.5426621160409556\n",
      "279 0.5494880546075085\n",
      "280 0.5494880546075085\n",
      "281 0.5767918088737202\n",
      "282 0.552901023890785\n",
      "283 0.5426621160409556\n",
      "284 0.5426621160409556\n",
      "285 0.552901023890785\n",
      "286 0.552901023890785\n",
      "287 0.5563139931740614\n",
      "288 0.5392491467576792\n",
      "289 0.5563139931740614\n",
      "290 0.5494880546075085\n",
      "291 0.5494880546075085\n",
      "292 0.552901023890785\n",
      "293 0.5426621160409556\n",
      "294 0.552901023890785\n",
      "295 0.5494880546075085\n",
      "296 0.5597269624573379\n",
      "297 0.5392491467576792\n",
      "298 0.5494880546075085\n",
      "299 0.5392491467576792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "for i in range(1,300):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "\n",
    "    dataset_size = len(X_train)\n",
    "    TwoDim_dataset = X_train.reshape(dataset_size,-1)\n",
    "\n",
    "    # fitting the model\n",
    "    knn.fit(TwoDim_dataset, Y_train)\n",
    "\n",
    "\n",
    "    # predict the response\n",
    "    dataset_size = len(X_test)\n",
    "    TwoDim_dataset = X_test.reshape(dataset_size,-1)\n",
    "    pred = knn.predict(TwoDim_dataset)\n",
    "    accu = knn.score(TwoDim_dataset, Y_test)\n",
    "    accuracy = []\n",
    "    for u,j in zip(pred, Y_test):\n",
    "        if u == j:\n",
    "            accuracy.append(1)\n",
    "        else:\n",
    "            accuracy.append(0)\n",
    "\n",
    "    accurate_predictions = [x for x in accuracy if x == 1]\n",
    "    acc = (len(accurate_predictions) / len(accuracy))\n",
    "\n",
    "    print(i, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bikal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 217)\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "TwoDim_dataset = X_train.reshape(dataset_size,-1)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(TwoDim_dataset, Y_train)\n",
    "\n",
    "\n",
    "# predict the response\n",
    "dataset_size = len(X_test)\n",
    "TwoDim_dataset = X_test.reshape(dataset_size,-1)\n",
    "pred = knn.predict(TwoDim_dataset)\n",
    "accu = knn.score(TwoDim_dataset, Y_test)\n",
    "accuracy = []\n",
    "for u,j in zip(pred, Y_test):\n",
    "    if u == j:\n",
    "        accuracy.append(1)\n",
    "    else:\n",
    "        accuracy.append(0)\n",
    "\n",
    "accurate_predictions = [x for x in accuracy if x == 1]\n",
    "acc = (len(accurate_predictions) / len(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5938566552901023"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Saving the KNN Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"KNN-ModelMonthly59.pickle\", \"wb\")\n",
    "pickle.dump(knn, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.39922515,\n",
       "        0.41153838, 0.40758761, 0.40745592, 0.36630208, 0.45269222],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.55678258,\n",
       "        0.16054829, 0.00598181, 0.05977971, 0.15200467, 0.79843759]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
